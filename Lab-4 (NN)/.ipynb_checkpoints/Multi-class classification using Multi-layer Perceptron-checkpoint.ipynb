{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "134efdda",
   "metadata": {},
   "source": [
    "### This notebook presents a multi-layer perceptron for multi-class classification using softmax activation \n",
    "\n",
    "## Stepwise Implementation:\n",
    "\n",
    "### 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794dab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Flatten \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.layers import Activation \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe16122",
   "metadata": {},
   "source": [
    "### 2. Load the MNIST dataset from keras library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed977f3a",
   "metadata": {},
   "source": [
    "TensorFlow allows us to read the MNIST dataset and we can load it directly in the program as a train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2405a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4975464",
   "metadata": {},
   "source": [
    "### 3. Convert the pixels into floating-point values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51904deb",
   "metadata": {},
   "source": [
    "The pixel values range from 0 to 256, apart from 0 the range is 255. Dividing all the values by 255 to convert the range from 0 to 1.\n",
    "\n",
    "Converting the pixel values into floating-point values helps in computation becomes easier and faster. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92962e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast the records into float values \n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32') \n",
    "  \n",
    "# normalize image pixel values by dividing  \n",
    "# by 255 \n",
    "gray_scale = 255\n",
    "x_train /= gray_scale \n",
    "x_test /= gray_scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae2fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data:\", x_train.shape) \n",
    "print(\"Test data:\", x_test.shape) \n",
    "print(\"Training label data:\", y_train.shape) \n",
    "print(\"Test label data:\", y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6df207",
   "metadata": {},
   "source": [
    "In total there are 60,000 records in the training dataset and 10,000 records in the test dataset and every image is of the size 28Ã—28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d646c",
   "metadata": {},
   "source": [
    "### 4. Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a008ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10, 10) \n",
    "k = 0\n",
    "for i in range(10): \n",
    "    for j in range(10): \n",
    "        ax[i][j].imshow(x_train[k].reshape(28, 28),  \n",
    "                        aspect='auto') \n",
    "        k += 1\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2acebb",
   "metadata": {},
   "source": [
    "### 5. Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([ \n",
    "    \n",
    "    # reshape 28 row * 28 column data to 28*28 rows \n",
    "    Flatten(input_shape=(28, 28)), \n",
    "    \n",
    "      # hidden dense layer 1 \n",
    "    Dense(128, activation='relu', name='L1'),   \n",
    "    \n",
    "    # hidden dense layer 2 \n",
    "    Dense(64, activation='relu', name='L2'),  \n",
    "    \n",
    "      # output layer \n",
    "    Dense(10, activation='softmax', name='L3'),   ## prefer softmax activation for multi-class classification\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82273c23",
   "metadata": {},
   "source": [
    "The Sequential model creates the model layer-by-layer as needed in a multi-layer perceptron, with a sigmoid activation function at each of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc725f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e425a292",
   "metadata": {},
   "source": [
    "#### Get the weights and bias for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1 = model.get_layer(\"L1\").get_weights()\n",
    "W2, b2 = model.get_layer(\"L2\").get_weights()\n",
    "W3, b3 = model.get_layer(\"L3\").get_weights()\n",
    "\n",
    "print(f\"W1{W1.shape}:\\n\", W1, f\"\\nb1{b1.shape}:\", b1)\n",
    "print(f\"W2{W2.shape}:\\n\", W2, f\"\\nb2{b2.shape}:\", b2)\n",
    "print(f\"W3{W3.shape}:\\n\", W3, f\"\\nb3{b3.shape}:\", b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f100b8f3",
   "metadata": {},
   "source": [
    "### 6. Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0935c8b2",
   "metadata": {},
   "source": [
    "The model.compile statement defines a loss function and specifies a compile optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d17a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d1f8ca",
   "metadata": {},
   "source": [
    "### 7. Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da869c85",
   "metadata": {},
   "source": [
    "The model.fit statement runs gradient descent and fits the weights to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b28562",
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd1af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the change in weights and biases at each layer\n",
    "W1, b1 = model.get_layer(\"L1\").get_weights()\n",
    "W2, b2 = model.get_layer(\"L2\").get_weights()\n",
    "W3, b3 = model.get_layer(\"L3\").get_weights()\n",
    "\n",
    "print(f\"W1{W1.shape}:\\n\", W1, f\"\\nb1{b1.shape}:\", b1)\n",
    "print(f\"W2{W2.shape}:\\n\", W2, f\"\\nb2{b2.shape}:\", b2)\n",
    "print(f\"W3{W3.shape}:\\n\", W3, f\"\\nb3{b3.shape}:\", b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b82201",
   "metadata": {},
   "source": [
    "### 8. Find Accuracy and loss for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose = 1) \n",
    "print('test loss, test acc:', test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5432f2",
   "metadata": {},
   "source": [
    "### 9. Evalaute other performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f97575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Predict class probabilities for the test data\n",
    "y_pred_probs = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Calculate Precision, Recall, and F1-score\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dcc710",
   "metadata": {},
   "source": [
    "# Evaluative Section: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3658e202",
   "metadata": {},
   "source": [
    "## Construct a Multi-layer Perceptron model for the CIFAR-10 dataset and evaluate its performance. Evalate model performace with respect to sigmoid vs softmax activation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e769420",
   "metadata": {},
   "source": [
    "#### About the dataset: The CIFAR (Canadian Institute For Advanced Research)-10 is one of the most widely used datasets for machine learning research.  It consists of 60,000 32x32 color images in 10 classes, with 6000 images per class. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd08e84",
   "metadata": {},
   "source": [
    "### Download the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9694033",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
